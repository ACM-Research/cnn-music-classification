{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip files\n",
    "import zipfile\n",
    "with zipfile.ZipFile('./acousticbrainz.zip', 'r') as zip:\n",
    "    zip.extractall('extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subfiles and move everything around to be more convenient\n",
    "import tarfile\n",
    "from os import listdir, mkdir, replace\n",
    "import bz2\n",
    "\n",
    "mkdir('./tsvs')\n",
    "for filename in listdir('./extracted'):\n",
    "    if '.tar.bz2' in filename:\n",
    "      tarfile.open('./extracted/' + filename).extractall('./train' if 'train' in filename else './validation')\n",
    "    elif 'tsv.bz2' in filename:\n",
    "      data = bz2.BZ2File('./extracted/' + filename).read()\n",
    "      open('./tsvs/' + filename[:-4], 'wb').write(data)\n",
    "    \n",
    "for folder in listdir('./train/acousticbrainz-mediaeval-train'):\n",
    "    for filename in listdir('./train/acousticbrainz-mediaeval-train/' + folder):\n",
    "        replace('./train/acousticbrainz-mediaeval-train/' + folder + '/' + filename, './train/' + filename)\n",
    "\n",
    "for folder in listdir('./validation/acousticbrainz-mediaeval-validation'):\n",
    "    for filename in listdir('./validation/acousticbrainz-mediaeval-validation/' + folder):\n",
    "        replace('./validation/acousticbrainz-mediaeval-validation/' + folder + '/' + filename, './validation/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the data and preprocess it into a usable form\n",
    "import json\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "properties = [\n",
    "    'metadata/audio_properties/length',\n",
    "    'rhythm/bpm',\n",
    "    'rhythm/danceability',\n",
    "    'tonal/key_scale', # 0=minor or 1=major\n",
    "    # Key_key, key_scale, chords_key, chords_scale are all\n",
    "]\n",
    "\"\"\"\n",
    "    'rhythm/onset_rate',\n",
    "    'tonal/tuning_equal_tempered_deviation',\n",
    "    'tonal/chords_changes_rate',\n",
    "    'tonal/tuning_diatonic_strength',\n",
    "    'tonal/chords_number_rate',\n",
    "    'tonal/tuning_frequency',\n",
    "    'tonal/tuning_nontempered_energy_ratio',\n",
    "    'tonal/key_strength',\n",
    "    'tonal/chords_strength/dmean2',\n",
    "    'tonal/chords_strength/median',\n",
    "    'tonal/chords_strength/min',\n",
    "    'tonal/chords_strength/dvar2',\n",
    "    'tonal/chords_strength/dvar',\n",
    "    'tonal/chords_strength/dmean',\n",
    "    'tonal/chords_strength/max',\n",
    "    'tonal/chords_strength/var',\n",
    "    'tonal/chords_strength/mean',\n",
    "    'tonal/hpcp_entropy/dmean2',\n",
    "    'tonal/hpcp_entropy/median',\n",
    "    'tonal/hpcp_entropy/min',\n",
    "    'tonal/hpcp_entropy/dvar2',\n",
    "    'tonal/hpcp_entropy/dvar',\n",
    "    'tonal/hpcp_entropy/dmean',\n",
    "    'tonal/hpcp_entropy/max',\n",
    "    'tonal/hpcp_entropy/var',\n",
    "    'tonal/hpcp_entropy/mean',\n",
    "\"\"\"\n",
    "\n",
    "X_train = []\n",
    "X_validation = []\n",
    "\n",
    "y_train = []\n",
    "y_validation = []\n",
    "\n",
    "all_genres = set()\n",
    "\n",
    "def process_tsv(file_path, is_validation=False):\n",
    "    with open(file_path) as tsv:\n",
    "        tsv.readline()\n",
    "        for _ in range(100000):\n",
    "            line = tsv.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            entries = line.split('\\t')\n",
    "            \n",
    "            genres = [genre for genre in entries[2:] if genre != '' and genre != '\\n']\n",
    "            for genre in genres:\n",
    "                all_genres.add(genre)\n",
    "            if not is_validation:\n",
    "                y_train.append(genres)\n",
    "            else:\n",
    "                y_validation.append(genres)\n",
    "\n",
    "\n",
    "            with open(('./train/' if not is_validation else './validation/') + entries[0] + '.json') as file:\n",
    "                song = json.load(file)\n",
    "                datapoint = []\n",
    "                for property in properties:\n",
    "                    path = property.split('/')\n",
    "\n",
    "                    temp = song\n",
    "                    for partial in path:\n",
    "                        temp = temp[partial]\n",
    "\n",
    "                    if partial == 'key_scale': # edge case\n",
    "                        if temp == 'minor':\n",
    "                            temp = 0\n",
    "                        else:\n",
    "                            temp = 1\n",
    "\n",
    "                    datapoint.append(temp)\n",
    "                datapoint = np.array(datapoint)\n",
    "                if is_validation:\n",
    "                    X_validation.append(datapoint)\n",
    "                else:\n",
    "                    X_train.append(datapoint)\n",
    "\n",
    "process_tsv('./tsvs/acousticbrainz-mediaeval-discogs-train.tsv')\n",
    "process_tsv('./tsvs/acousticbrainz-mediaeval-discogs-validation.tsv', is_validation=True)\n",
    "\n",
    "all_genres = list(all_genres) # contains all the genres and their indices\n",
    "for i, datapoint in enumerate(y_train):\n",
    "    processed_datapoint = []\n",
    "    for genre in all_genres:\n",
    "        processed_datapoint.append(int(genre in datapoint))\n",
    "    y_train[i] = processed_datapoint\n",
    "\n",
    "for i, datapoint in enumerate(y_validation):\n",
    "    processed_datapoint = []\n",
    "    for genre in all_genres:\n",
    "        processed_datapoint.append(int(genre in datapoint))\n",
    "    y_validation[i] = processed_datapoint\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_validation = np.array(X_validation)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_validation = np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 30)]              0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 318)               9858      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,858\n",
      "Trainable params: 9,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model and give a summary\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "input = layers.Input(shape=(len(properties),))\n",
    "model = Model(input, layers.Dense(len(all_genres), activation='relu')(input))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 3.2764 - accuracy: 0.0000e+00 - val_loss: 3.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0797 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.0796 - accuracy: 0.0000e+00 - val_loss: 3.0802 - val_accuracy: 0.0000e+00\n",
      "3125/3125 [==============================] - 2s 664us/step - loss: 3.0802 - accuracy: 0.0000e+00\n",
      "Validation loss and accuracy: [3.0801994800567627, 0.0]\n",
      "INFO:tensorflow:Assets written to: trained_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Train and save the model \n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_validation, y_validation))\n",
    "score = model.evaluate(X_validation, y_validation, verbose=1)\n",
    "print('Validation loss and accuracy:', score)\n",
    "model.save('trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "318\n",
      "[[74.340355   0.         0.         7.9846654 30.34112    0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.        62.462246   0.         0.        75.62224\n",
      "   0.         0.        48.710922   0.        56.399654   0.\n",
      "  63.26691   43.401943  51.139717   0.        22.255716   0.\n",
      "   0.        49.966183   0.         0.        33.699265   0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        17.631767  34.61928\n",
      "   0.         0.         0.         0.        16.265888   0.\n",
      "   0.        32.91748   35.18291    0.         0.        29.790016\n",
      "   0.         0.         0.        24.778996   0.         0.\n",
      "  70.60348   45.316772   0.         0.         0.         0.\n",
      "  40.813644   0.         0.        29.139893   0.         0.\n",
      "   0.         0.         0.        36.052235   0.         0.\n",
      "   0.        40.42734    0.         0.         0.         0.\n",
      "  42.728756  41.868225   0.         0.         0.         0.\n",
      "   0.        66.39431   61.722725  38.593998   8.252701   0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.        57.365654   0.         0.\n",
      "  12.517237  10.289955  57.815628   0.        40.71659   20.579485\n",
      "   0.         0.         0.         0.         0.        41.413746\n",
      "   0.        47.82657    0.        29.827713   0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         6.5784435  0.         0.         0.\n",
      "  36.04136    0.        34.303886  71.670265  16.84406    0.\n",
      "  57.50103   25.557775   0.         0.         0.         0.\n",
      "   0.        43.221214   0.         0.         0.         0.\n",
      "   0.        25.507551   0.        20.799934   0.         0.\n",
      "   0.         0.        43.426834   0.        68.381996  47.503296\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.        66.025856\n",
      "   0.        24.588186   0.         0.         0.         0.\n",
      "  33.053688   0.         0.         0.         0.        24.851126\n",
      "  28.007885   0.        36.61644    0.         0.         0.\n",
      "   0.         0.         0.        35.92676    0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.        39.15445    0.         0.         0.\n",
      "  56.76472    0.         0.        28.507227   0.         0.\n",
      "   0.        22.825518  27.491621   0.        12.373062   0.\n",
      "   0.         0.         0.         0.        24.570368   0.\n",
      "   0.        70.79883   35.59254    0.         0.        20.30429\n",
      "   0.         0.         0.        24.292791   0.         0.\n",
      "  57.000603   0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "  26.140985   0.         0.         0.         0.         0.\n",
      "   0.         0.        68.99053   70.67884    0.        56.77204\n",
      "  39.476437  61.462414  49.893627   0.         0.         0.\n",
      "  20.398586   0.        30.05952    0.        68.44868    0.\n",
      "  23.161314   0.         0.         0.         0.        61.770138\n",
      "   0.        74.61877    0.         0.         0.         0.\n",
      "   0.         0.        69.640816   0.         0.        16.361643 ]]\n",
      "75.62224\n",
      "17\n",
      "hip hop\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "result = model.predict(np.array(X_train[0]).reshape(1,len(properties)))\n",
    "print(len(result[0]))\n",
    "print(result)\n",
    "print(max(result[0]))\n",
    "print(list(result[0]).index(max(result[0])))\n",
    "print(all_genres[17])\n",
    "print(y_train[0][17])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
